{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RSSI_DT.ipynb",
      "provenance": [],
      "mount_file_id": "1Bsy2zEIxdBbDQXTqOorg0FC3Hoo8ewE5",
      "authorship_tag": "ABX9TyP5UpJoCrwxJgf6iwltZg1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetslovely/Wifi_RSSI_localization/blob/main/RSSI_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJIHro5XxYUm"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0DY3Xblxg7k"
      },
      "source": [
        "fetch_training_sample= '/content/drive/My Drive/UJIndoorLoc/UJIndoorLoc/trainingData.csv'\r\n",
        "fetch_validation_sample= '/content/drive/My Drive/UJIndoorLoc/UJIndoorLoc/validationData.csv'\r\n",
        "training_data = pd.read_csv(fetch_training_sample)\r\n",
        "validation_data = pd.read_csv(fetch_validation_sample)\r\n",
        "df= pd.DataFrame(data=training_data)\r\n",
        "df1 = pd.DataFrame(data=validation_data)\r\n",
        "df['BUILDINGID']=df.BUILDINGID.astype(str)\r\n",
        "df1['BUILDINGID']=df.BUILDINGID.astype(str)\r\n",
        "df['FLOOR']=df.FLOOR.astype(str)\r\n",
        "df1['FLOOR']=df.FLOOR.astype(str)\r\n",
        "df['newfeature'] = df[['BUILDINGID', 'FLOOR']].apply(lambda x: '.'.join(x), axis=1)\r\n",
        "df[['newfeature']] = df[['newfeature']].apply(pd.to_numeric) \r\n",
        "df1['newfeature'] = df[['BUILDINGID', 'FLOOR']].apply(lambda x: '.'.join(x), axis=1)\r\n",
        "df1[['newfeature']] = df1[['newfeature']].apply(pd.to_numeric) \r\n",
        "modified_training_data = pd.concat([df,df1], ignore_index=True)\r\n",
        "modified_training_data['newfeature']=1000*modified_training_data['newfeature']\r\n",
        "modified_training_data['newfeature'] = modified_training_data['newfeature'].astype(int) \r\n",
        "\r\n",
        "x_modified_training_data = modified_training_data.drop(columns=['LONGITUDE',\"LATITUDE\", \"FLOOR\", \"BUILDINGID\", \"SPACEID\", \"RELATIVEPOSITION\", \"USERID\", \"PHONEID\", \"TIMESTAMP\", \"newfeature\"])\r\n",
        "y_modified_training_data = modified_training_data.loc[:,['LONGITUDE',\"LATITUDE\", \"FLOOR\", \"BUILDINGID\", \"SPACEID\",\"newfeature\"]]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hbQ8Mljx6Pb"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x_modified_training_data,y_modified_training_data, test_size= 0.33,random_state=42)\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB00Q7H9yT4P",
        "outputId": "911693a5-0b92-4642-f8c4-860b3fea0e5c"
      },
      "source": [
        "error_newfeature = []\r\n",
        "error = []\r\n",
        "error_building = []\r\n",
        "\r\n",
        "classifier = LogisticRegression(random_state=0)\r\n",
        "classifier.fit(X_train, Y_train['newfeature'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "y_pred_pro=classifier.predict_proba(X_test)\r\n",
        "y_pred_score=classifier.score(X_test,Y_test['newfeature'])\r\n",
        "print(y_pred_pro)\r\n",
        "print(y_pred_score)\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.30551293e-03 9.98640686e-01 7.03614090e-06 ... 9.03773516e-11\n",
            "  8.14064793e-09 2.51662466e-06]\n",
            " [2.79023977e-08 6.71947889e-10 6.21303889e-10 ... 1.28967126e-10\n",
            "  9.40931821e-01 1.15151510e-04]\n",
            " [9.80939398e-12 2.43210167e-11 2.71090585e-11 ... 1.20654463e-11\n",
            "  1.63557789e-12 9.96182187e-15]\n",
            " ...\n",
            " [5.36997226e-23 1.92502591e-25 9.99999999e-01 ... 1.52953049e-26\n",
            "  1.46098284e-39 8.29569785e-21]\n",
            " [1.07471549e-06 3.33501450e-08 4.50175864e-08 ... 6.65737541e-04\n",
            "  4.04954128e-05 8.20554026e-10]\n",
            " [6.62490782e-06 3.51781939e-07 6.53735875e-07 ... 3.98950697e-05\n",
            "  9.99350709e-01 4.37815892e-04]]\n",
            "0.9067088972070256\n",
            "[[335  21   0   0   0   0   0   0   0   0   0   2   0]\n",
            " [ 27 387  11   0   0   0   4   0   0   0   0   9   0]\n",
            " [  0   8 425  35   0   1   3   0   0   0   0   7   0]\n",
            " [  0   1  30 440   0   0   0   0   0   0   0   4   0]\n",
            " [  0   0   0   0 434  17   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0  26 444  14   0   0   0   0   3   0]\n",
            " [  5   9   7   6   8  12 472   8   4   3   1  45   2]\n",
            " [  0   0   0   0   0   0  16 301   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0  11 599  17   0   0   0]\n",
            " [  0   0   0   0   0   5   2   0  19 691  17   2   0]\n",
            " [  0   0   0   0   0   0   1   0   0  21 471  19   0]\n",
            " [  6   6   8  11   1  15  60   8   1   9  12 953  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  29 346]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       358\n",
            "         100       0.90      0.88      0.89       438\n",
            "         200       0.88      0.89      0.89       479\n",
            "         300       0.89      0.93      0.91       475\n",
            "        1000       0.93      0.96      0.94       454\n",
            "        1100       0.90      0.91      0.91       487\n",
            "        1200       0.82      0.81      0.82       582\n",
            "        1300       0.92      0.95      0.93       318\n",
            "        2000       0.96      0.96      0.96       627\n",
            "        2100       0.93      0.94      0.94       736\n",
            "        2200       0.94      0.92      0.93       512\n",
            "        2300       0.89      0.86      0.87      1105\n",
            "        2400       0.95      0.92      0.94       375\n",
            "\n",
            "    accuracy                           0.91      6946\n",
            "   macro avg       0.91      0.91      0.91      6946\n",
            "weighted avg       0.91      0.91      0.91      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx7WKLFW9zOJ",
        "outputId": "00281d67-da02-4589-c3b8-c16f538eda98"
      },
      "source": [
        "from sklearn import svm\r\n",
        "classifier = svm.SVC()\r\n",
        "classifier.fit(X_train, Y_train['newfeature'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[344  13   0   0   0   0   0   0   0   0   0   1   0]\n",
            " [ 18 407   4   1   0   0   0   0   0   0   0   8   0]\n",
            " [  0   1 426  34   0   0   0   0   0   0   0  18   0]\n",
            " [  0   1  17 448   0   0   0   0   0   0   0   9   0]\n",
            " [  0   0   0   0 433  19   0   0   2   0   0   0   0]\n",
            " [  0   0   0   0  14 469   3   0   0   0   0   1   0]\n",
            " [  6  11   7   5   4  15 471  14   4   4   1  39   1]\n",
            " [  0   0   0   0   0   0  18 284  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 614  13   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9 700  12  15   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14 481  17   0]\n",
            " [  5  16  11  12   1  14  40   6   2   5   1 988   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  26 348]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       358\n",
            "         100       0.91      0.93      0.92       438\n",
            "         200       0.92      0.89      0.90       479\n",
            "         300       0.90      0.94      0.92       475\n",
            "        1000       0.96      0.95      0.96       454\n",
            "        1100       0.91      0.96      0.93       487\n",
            "        1200       0.89      0.81      0.85       582\n",
            "        1300       0.93      0.89      0.91       318\n",
            "        2000       0.95      0.98      0.96       627\n",
            "        2100       0.95      0.95      0.95       736\n",
            "        2200       0.97      0.94      0.96       512\n",
            "        2300       0.88      0.89      0.89      1105\n",
            "        2400       0.99      0.93      0.96       375\n",
            "\n",
            "    accuracy                           0.92      6946\n",
            "   macro avg       0.93      0.93      0.93      6946\n",
            "weighted avg       0.92      0.92      0.92      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioy_KXKh9_63",
        "outputId": "5270636b-8139-46e2-ece9-723db9e24b47"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "classifier = DecisionTreeClassifier(max_depth=2)\r\n",
        "classifier.fit(X_train, Y_train['newfeature'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "y_pred_pro=classifier.predict_proba(X_test)\r\n",
        "print(y_pred_pro)\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "\r\n",
        "\r\n",
        "classifier.fit(X_train, Y_train['FLOOR'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "y_pred_pro=classifier.predict_proba(X_test)\r\n",
        "print(y_pred_pro)\r\n",
        "print(confusion_matrix(Y_test['FLOOR'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['FLOOR'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.06803644 0.08897073 0.09342896 ... 0.04274084 0.08993991 0.05902307]\n",
            " [0.         0.         0.         ... 0.05932203 0.10653753 0.01331719]\n",
            " [0.         0.         0.         ... 0.00248756 0.00995025 0.        ]\n",
            " ...\n",
            " [0.06803644 0.08897073 0.09342896 ... 0.04274084 0.08993991 0.05902307]\n",
            " [0.         0.         0.         ... 0.26648097 0.55663881 0.05803157]\n",
            " [0.         0.         0.         ... 0.26648097 0.55663881 0.05803157]]\n",
            "[[  0   0   0   0   0   0 358   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 438   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 479   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 475   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 454   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 487   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 558   0   5   8   0  11   0]\n",
            " [  0   0   0   0   0   0 318   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 185   0 317 115   0  10   0]\n",
            " [  0   0   0   0   0   0 351   0  45 225   0 115   0]\n",
            " [  0   0   0   0   0   0 217   0   3  28   0 264   0]\n",
            " [  0   0   0   0   0   0 452   0   2  35   0 616   0]\n",
            " [  0   0   0   0   0   0 309   0   0   1   0  65   0]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       358\n",
            "         100       0.00      0.00      0.00       438\n",
            "         200       0.00      0.00      0.00       479\n",
            "         300       0.00      0.00      0.00       475\n",
            "        1000       0.00      0.00      0.00       454\n",
            "        1100       0.00      0.00      0.00       487\n",
            "        1200       0.11      0.96      0.20       582\n",
            "        1300       0.00      0.00      0.00       318\n",
            "        2000       0.85      0.51      0.63       627\n",
            "        2100       0.55      0.31      0.39       736\n",
            "        2200       0.00      0.00      0.00       512\n",
            "        2300       0.57      0.56      0.56      1105\n",
            "        2400       0.00      0.00      0.00       375\n",
            "\n",
            "    accuracy                           0.25      6946\n",
            "   macro avg       0.16      0.18      0.14      6946\n",
            "weighted avg       0.23      0.25      0.20      6946\n",
            " new combined feature \n",
            "\n",
            "[[0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]\n",
            " [0.6219346  0.3113079  0.04700272 0.01907357 0.0006812 ]\n",
            " [0.6219346  0.3113079  0.04700272 0.01907357 0.0006812 ]\n",
            " ...\n",
            " [0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]\n",
            " [0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]\n",
            " [0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 421    0 1002   16    0]\n",
            " [ 240    0 1368   53    0]\n",
            " [  33    0 1372  159    9]\n",
            " [  13    0 1369  500   16]\n",
            " [   1    0   94   77  203]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.29      0.39      1439\n",
            "           1       0.00      0.00      0.00      1661\n",
            "           2       0.26      0.87      0.40      1573\n",
            "           3       0.62      0.26      0.37      1898\n",
            "           4       0.89      0.54      0.67       375\n",
            "\n",
            "    accuracy                           0.36      6946\n",
            "   macro avg       0.47      0.39      0.37      6946\n",
            "weighted avg       0.40      0.36      0.31      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQiYm9fqAFuz",
        "outputId": "19a5377d-4ba1-4c4e-8aa6-7eea7bcfca13"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import VotingClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "log_clf = LogisticRegression()\r\n",
        "rnd_clf = RandomForestClassifier()\r\n",
        "svm_clf = SVC()\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc',svm_clf)],\r\n",
        "                              voting= 'hard')\r\n",
        "voting_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "for clf in (log_clf,rnd_clf, svm_clf,voting_clf):\r\n",
        "    clf.fit(X_train,Y_train['newfeature'])\r\n",
        "    y_pred= clf.predict(X_test)\r\n",
        "    print(accuracy_score(Y_test['newfeature'],y_pred))\r\n",
        "    print(\"***********************************\")\r\n",
        "    print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "    print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9067088972070256\n",
            "***********************************\n",
            "[[335  21   0   0   0   0   0   0   0   0   0   2   0]\n",
            " [ 27 387  11   0   0   0   4   0   0   0   0   9   0]\n",
            " [  0   8 425  35   0   1   3   0   0   0   0   7   0]\n",
            " [  0   1  30 440   0   0   0   0   0   0   0   4   0]\n",
            " [  0   0   0   0 434  17   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0  26 444  14   0   0   0   0   3   0]\n",
            " [  5   9   7   6   8  12 472   8   4   3   1  45   2]\n",
            " [  0   0   0   0   0   0  16 301   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0  11 599  17   0   0   0]\n",
            " [  0   0   0   0   0   5   2   0  19 691  17   2   0]\n",
            " [  0   0   0   0   0   0   1   0   0  21 471  19   0]\n",
            " [  6   6   8  11   1  15  60   8   1   9  12 953  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  29 346]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       358\n",
            "         100       0.90      0.88      0.89       438\n",
            "         200       0.88      0.89      0.89       479\n",
            "         300       0.89      0.93      0.91       475\n",
            "        1000       0.93      0.96      0.94       454\n",
            "        1100       0.90      0.91      0.91       487\n",
            "        1200       0.82      0.81      0.82       582\n",
            "        1300       0.92      0.95      0.93       318\n",
            "        2000       0.96      0.96      0.96       627\n",
            "        2100       0.93      0.94      0.94       736\n",
            "        2200       0.94      0.92      0.93       512\n",
            "        2300       0.89      0.86      0.87      1105\n",
            "        2400       0.95      0.92      0.94       375\n",
            "\n",
            "    accuracy                           0.91      6946\n",
            "   macro avg       0.91      0.91      0.91      6946\n",
            "weighted avg       0.91      0.91      0.91      6946\n",
            " new combined feature \n",
            "\n",
            "0.954362222862079\n",
            "***********************************\n",
            "[[357   1   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2 435   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1 477   1   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1 474   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 454   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   3 484   0   0   0   0   0   0   0]\n",
            " [  4  18  13  11   5   7 476   7   6  17   3  14   1]\n",
            " [  0   0   0   0   0   0   1 301  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 626   1   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2 733   1   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3 507   2   0]\n",
            " [ 10  26  26  21   1  20  32   9   1  12   8 937   2]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   6 368]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98       358\n",
            "         100       0.90      0.99      0.95       438\n",
            "         200       0.92      1.00      0.96       479\n",
            "         300       0.93      1.00      0.97       475\n",
            "        1000       0.98      1.00      0.99       454\n",
            "        1100       0.95      0.99      0.97       487\n",
            "        1200       0.94      0.82      0.87       582\n",
            "        1300       0.95      0.95      0.95       318\n",
            "        2000       0.96      1.00      0.98       627\n",
            "        2100       0.96      1.00      0.98       736\n",
            "        2200       0.98      0.99      0.98       512\n",
            "        2300       0.98      0.85      0.91      1105\n",
            "        2400       0.99      0.98      0.99       375\n",
            "\n",
            "    accuracy                           0.95      6946\n",
            "   macro avg       0.95      0.97      0.96      6946\n",
            "weighted avg       0.96      0.95      0.95      6946\n",
            " new combined feature \n",
            "\n",
            "0.9232651885977541\n",
            "***********************************\n",
            "[[344  13   0   0   0   0   0   0   0   0   0   1   0]\n",
            " [ 18 407   4   1   0   0   0   0   0   0   0   8   0]\n",
            " [  0   1 426  34   0   0   0   0   0   0   0  18   0]\n",
            " [  0   1  17 448   0   0   0   0   0   0   0   9   0]\n",
            " [  0   0   0   0 433  19   0   0   2   0   0   0   0]\n",
            " [  0   0   0   0  14 469   3   0   0   0   0   1   0]\n",
            " [  6  11   7   5   4  15 471  14   4   4   1  39   1]\n",
            " [  0   0   0   0   0   0  18 284  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 614  13   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9 700  12  15   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14 481  17   0]\n",
            " [  5  16  11  12   1  14  40   6   2   5   1 988   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  26 348]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       358\n",
            "         100       0.91      0.93      0.92       438\n",
            "         200       0.92      0.89      0.90       479\n",
            "         300       0.90      0.94      0.92       475\n",
            "        1000       0.96      0.95      0.96       454\n",
            "        1100       0.91      0.96      0.93       487\n",
            "        1200       0.89      0.81      0.85       582\n",
            "        1300       0.93      0.89      0.91       318\n",
            "        2000       0.95      0.98      0.96       627\n",
            "        2100       0.95      0.95      0.95       736\n",
            "        2200       0.97      0.94      0.96       512\n",
            "        2300       0.88      0.89      0.89      1105\n",
            "        2400       0.99      0.93      0.96       375\n",
            "\n",
            "    accuracy                           0.92      6946\n",
            "   macro avg       0.93      0.93      0.93      6946\n",
            "weighted avg       0.92      0.92      0.92      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9380938669737978\n",
            "***********************************\n",
            "[[349   9   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 17 415   5   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   4 450  25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1  11 463   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 444  10   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  12 474   1   0   0   0   0   0   0]\n",
            " [  7  13  10   9   6  12 480  10   4   3   1  27   0]\n",
            " [  0   0   0   0   0   0  13 289  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 616  11   0   0   0]\n",
            " [  0   0   0   0   0   0   1   0   8 718   9   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0  11 492   8   0]\n",
            " [  5  18  22  15   1  18  36   6   2   4   1 973   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  21 353]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95       358\n",
            "         100       0.90      0.95      0.92       438\n",
            "         200       0.90      0.94      0.92       479\n",
            "         300       0.90      0.97      0.94       475\n",
            "        1000       0.96      0.98      0.97       454\n",
            "        1100       0.92      0.97      0.95       487\n",
            "        1200       0.90      0.82      0.86       582\n",
            "        1300       0.95      0.91      0.93       318\n",
            "        2000       0.95      0.98      0.97       627\n",
            "        2100       0.96      0.98      0.97       736\n",
            "        2200       0.98      0.96      0.97       512\n",
            "        2300       0.94      0.88      0.91      1105\n",
            "        2400       0.99      0.94      0.96       375\n",
            "\n",
            "    accuracy                           0.94      6946\n",
            "   macro avg       0.94      0.94      0.94      6946\n",
            "weighted avg       0.94      0.94      0.94      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cugZykjaFirv",
        "outputId": "82d48a3f-edca-47ef-b233-efc9513b706e"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,max_samples=100, bootstrap=True, n_jobs=-1)\r\n",
        "bag_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "y_pred= bag_clf.predict(X_test)\r\n",
        "y_pred_pro= bag_clf.predict_proba(X_test)\r\n",
        "\r\n",
        "print(\"***********************************\")\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(\"***********************************\")\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********************************\n",
            "[[305  50   0   0   0   0   3   0   0   0   0   0   0]\n",
            " [ 24 398  12   4   0   0   0   0   0   0   0   0   0]\n",
            " [  6  17 425  29   0   0   2   0   0   0   0   0   0]\n",
            " [  0   0   1 474   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 361  67  26   0   0   0   0   0   0]\n",
            " [  0   0   0   0 103 350  34   0   0   0   0   0   0]\n",
            " [  3  25  20  12  10  79 382  13   6  19   3   9   1]\n",
            " [  0   0   0   0   0  17 129 170   0   0   0   2   0]\n",
            " [  0   0   0   0   1   0  11   0 604   7   0   4   0]\n",
            " [  0   0   0   0   0   0   0   0  34 662   5  35   0]\n",
            " [  0   0   0   0   0   0   3   0   0  28 386  95   0]\n",
            " [ 16  36  26  24   6  17  38   6   3  16   9 905   3]\n",
            " [  1   0   0   0   0   0   0   0   1   1   0 125 247]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.86       358\n",
            "         100       0.76      0.91      0.83       438\n",
            "         200       0.88      0.89      0.88       479\n",
            "         300       0.87      1.00      0.93       475\n",
            "        1000       0.75      0.80      0.77       454\n",
            "        1100       0.66      0.72      0.69       487\n",
            "        1200       0.61      0.66      0.63       582\n",
            "        1300       0.90      0.53      0.67       318\n",
            "        2000       0.93      0.96      0.95       627\n",
            "        2100       0.90      0.90      0.90       736\n",
            "        2200       0.96      0.75      0.84       512\n",
            "        2300       0.77      0.82      0.79      1105\n",
            "        2400       0.98      0.66      0.79       375\n",
            "\n",
            "    accuracy                           0.82      6946\n",
            "   macro avg       0.83      0.80      0.81      6946\n",
            "weighted avg       0.83      0.82      0.82      6946\n",
            " new combined feature \n",
            "\n",
            "***********************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhNeMVNaKsCT",
        "outputId": "059a8b86-30b3-4e8a-f443-44bae1618c83"
      },
      "source": [
        "accuracy_score(Y_test['newfeature'], y_pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.816153181687302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLElP7UKOexN"
      },
      "source": [
        "rnd_clf= RandomForestClassifier(n_estimators=500,max_leaf_nodes=20,n_jobs=-1)\r\n",
        "rnd_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "y_pred_rf= rnd_clf.predict(X_test)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwE0MgpsYKS5",
        "outputId": "95bf619d-3a66-488a-c256-3c10765b7ec5"
      },
      "source": [
        "print(confusion_matrix(Y_test['newfeature'], y_pred_rf),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred_rf),\"new combined feature \\n\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[211 143   1   0   0   0   3   0   0   0   0   0   0]\n",
            " [  7 410  20   1   0   0   0   0   0   0   0   0   0]\n",
            " [  0  38 232 201   0   0   8   0   0   0   0   0   0]\n",
            " [  0   0   2 473   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 334  95  25   0   0   0   0   0   0]\n",
            " [  0   0   0   0 114 332  41   0   0   0   0   0   0]\n",
            " [  2  30   7  20  22 109 342   3   7  16   2  22   0]\n",
            " [  0   0   0   0   0  25 174 108   0   0   0  11   0]\n",
            " [  0   0   0   0   1   0  11   0 602   8   0   5   0]\n",
            " [  0   0   0   0   0   0   0   0  43 635   1  57   0]\n",
            " [  0   0   0   0   0   0   6   0   0  34 298 174   0]\n",
            " [ 12  41  11  35   8  17  41   4   3  14   4 914   1]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0 179 195]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.59      0.71       358\n",
            "         100       0.62      0.94      0.75       438\n",
            "         200       0.85      0.48      0.62       479\n",
            "         300       0.65      1.00      0.79       475\n",
            "        1000       0.70      0.74      0.72       454\n",
            "        1100       0.57      0.68      0.62       487\n",
            "        1200       0.53      0.59      0.55       582\n",
            "        1300       0.94      0.34      0.50       318\n",
            "        2000       0.92      0.96      0.94       627\n",
            "        2100       0.90      0.86      0.88       736\n",
            "        2200       0.98      0.58      0.73       512\n",
            "        2300       0.67      0.83      0.74      1105\n",
            "        2400       0.99      0.52      0.68       375\n",
            "\n",
            "    accuracy                           0.73      6946\n",
            "   macro avg       0.79      0.70      0.71      6946\n",
            "weighted avg       0.77      0.73      0.73      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdm5ZdaYR8I"
      },
      "source": [
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(max_features= 'auto', max_leaf_nodes= 16), n_estimators= 500, max_samples=1, bootstrap=True, n_jobs=-1)\r\n",
        "bag_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "y_pred= bag_clf.predict(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5B8lxfHCXUB",
        "outputId": "624c9995-6314-437e-a904-52ed9c3de6d1"
      },
      "source": [
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0  358    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  438    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  479    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  475    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  454    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  487    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  582    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  318    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  627    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  736    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  512    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1105    0]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0  375    0]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       358\n",
            "         100       0.00      0.00      0.00       438\n",
            "         200       0.00      0.00      0.00       479\n",
            "         300       0.00      0.00      0.00       475\n",
            "        1000       0.00      0.00      0.00       454\n",
            "        1100       0.00      0.00      0.00       487\n",
            "        1200       0.00      0.00      0.00       582\n",
            "        1300       0.00      0.00      0.00       318\n",
            "        2000       0.00      0.00      0.00       627\n",
            "        2100       0.00      0.00      0.00       736\n",
            "        2200       0.00      0.00      0.00       512\n",
            "        2300       0.16      1.00      0.27      1105\n",
            "        2400       0.00      0.00      0.00       375\n",
            "\n",
            "    accuracy                           0.16      6946\n",
            "   macro avg       0.01      0.08      0.02      6946\n",
            "weighted avg       0.03      0.16      0.04      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktIABSwxM79r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}