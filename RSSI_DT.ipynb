{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RSSI_DT.ipynb",
      "provenance": [],
      "mount_file_id": "1Bsy2zEIxdBbDQXTqOorg0FC3Hoo8ewE5",
      "authorship_tag": "ABX9TyPp6Oj4Jh/YlbS8rovoBcgl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetslovely/Wifi_RSSI_localization/blob/main/RSSI_DT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJIHro5XxYUm"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sklearn\r\n",
        "from sklearn.model_selection import train_test_split \r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0DY3Xblxg7k"
      },
      "source": [
        "fetch_training_sample= '/content/drive/My Drive/UJIndoorLoc/UJIndoorLoc/trainingData.csv'\r\n",
        "fetch_validation_sample= '/content/drive/My Drive/UJIndoorLoc/UJIndoorLoc/validationData.csv'\r\n",
        "training_data = pd.read_csv(fetch_training_sample)\r\n",
        "validation_data = pd.read_csv(fetch_validation_sample)\r\n",
        "df= pd.DataFrame(data=training_data)\r\n",
        "df1 = pd.DataFrame(data=validation_data)\r\n",
        "df['BUILDINGID']=df.BUILDINGID.astype(str)\r\n",
        "df1['BUILDINGID']=df.BUILDINGID.astype(str)\r\n",
        "df['FLOOR']=df.FLOOR.astype(str)\r\n",
        "df1['FLOOR']=df.FLOOR.astype(str)\r\n",
        "df['newfeature'] = df[['BUILDINGID', 'FLOOR']].apply(lambda x: '.'.join(x), axis=1)\r\n",
        "df[['newfeature']] = df[['newfeature']].apply(pd.to_numeric) \r\n",
        "df1['newfeature'] = df[['BUILDINGID', 'FLOOR']].apply(lambda x: '.'.join(x), axis=1)\r\n",
        "df1[['newfeature']] = df1[['newfeature']].apply(pd.to_numeric) \r\n",
        "modified_training_data = pd.concat([df,df1], ignore_index=True)\r\n",
        "modified_training_data['newfeature']=1000*modified_training_data['newfeature']\r\n",
        "modified_training_data['newfeature'] = modified_training_data['newfeature'].astype(int) \r\n",
        "\r\n",
        "x_modified_training_data = modified_training_data.drop(columns=['LONGITUDE',\"LATITUDE\", \"FLOOR\", \"BUILDINGID\", \"SPACEID\", \"RELATIVEPOSITION\", \"USERID\", \"PHONEID\", \"TIMESTAMP\", \"newfeature\"])\r\n",
        "y_modified_training_data = modified_training_data.loc[:,['LONGITUDE',\"LATITUDE\", \"FLOOR\", \"BUILDINGID\", \"SPACEID\",\"newfeature\"]]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hbQ8Mljx6Pb"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x_modified_training_data,y_modified_training_data, test_size= 0.33,random_state=42)\r\n",
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train = scaler.transform(X_train)\r\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB00Q7H9yT4P",
        "outputId": "7a84e6a3-1e2c-425d-88ff-4008e3016e00"
      },
      "source": [
        "error_newfeature = []\r\n",
        "error = []\r\n",
        "error_building = []\r\n",
        "\r\n",
        "classifier = LogisticRegression(random_state=0)\r\n",
        "classifier.fit(X_train, Y_train['newfeature'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "y_pred_pro=classifier.predict_proba(X_test)\r\n",
        "y_pred_score=classifier.score(X_test,Y_test['newfeature'])\r\n",
        "print(y_pred_pro)\r\n",
        "print(y_pred_score)\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.30551202e-03 9.98640687e-01 7.03613843e-06 ... 9.03772850e-11\n",
            "  8.14064232e-09 2.51662322e-06]\n",
            " [2.79024151e-08 6.71948245e-10 6.21304318e-10 ... 1.28967275e-10\n",
            "  9.40931846e-01 1.15151581e-04]\n",
            " [9.80938918e-12 2.43210025e-11 2.71090482e-11 ... 1.20654428e-11\n",
            "  1.63557768e-12 9.96181933e-15]\n",
            " ...\n",
            " [5.36997578e-23 1.92502559e-25 9.99999999e-01 ... 1.52953063e-26\n",
            "  1.46098347e-39 8.29569716e-21]\n",
            " [1.07471499e-06 3.33501277e-08 4.50175691e-08 ... 6.65737380e-04\n",
            "  4.04954107e-05 8.20553698e-10]\n",
            " [6.62490760e-06 3.51781892e-07 6.53735859e-07 ... 3.98950683e-05\n",
            "  9.99350709e-01 4.37815923e-04]]\n",
            "0.9067088972070256\n",
            "[[335  21   0   0   0   0   0   0   0   0   0   2   0]\n",
            " [ 27 387  11   0   0   0   4   0   0   0   0   9   0]\n",
            " [  0   8 425  35   0   1   3   0   0   0   0   7   0]\n",
            " [  0   1  30 440   0   0   0   0   0   0   0   4   0]\n",
            " [  0   0   0   0 434  17   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0  26 444  14   0   0   0   0   3   0]\n",
            " [  5   9   7   6   8  12 472   8   4   3   1  45   2]\n",
            " [  0   0   0   0   0   0  16 301   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0  11 599  17   0   0   0]\n",
            " [  0   0   0   0   0   5   2   0  19 691  17   2   0]\n",
            " [  0   0   0   0   0   0   1   0   0  21 471  19   0]\n",
            " [  6   6   8  11   1  15  60   8   1   9  12 953  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  29 346]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       358\n",
            "         100       0.90      0.88      0.89       438\n",
            "         200       0.88      0.89      0.89       479\n",
            "         300       0.89      0.93      0.91       475\n",
            "        1000       0.93      0.96      0.94       454\n",
            "        1100       0.90      0.91      0.91       487\n",
            "        1200       0.82      0.81      0.82       582\n",
            "        1300       0.92      0.95      0.93       318\n",
            "        2000       0.96      0.96      0.96       627\n",
            "        2100       0.93      0.94      0.94       736\n",
            "        2200       0.94      0.92      0.93       512\n",
            "        2300       0.89      0.86      0.87      1105\n",
            "        2400       0.95      0.92      0.94       375\n",
            "\n",
            "    accuracy                           0.91      6946\n",
            "   macro avg       0.91      0.91      0.91      6946\n",
            "weighted avg       0.91      0.91      0.91      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lx7WKLFW9zOJ",
        "outputId": "50d48ce4-dbaf-4e27-85c5-ba8d2a6bf29a"
      },
      "source": [
        "from sklearn import svm\r\n",
        "classifier = svm.SVC()\r\n",
        "classifier.fit(X_train, Y_train['newfeature'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[344  13   0   0   0   0   0   0   0   0   0   1   0]\n",
            " [ 18 407   4   1   0   0   0   0   0   0   0   8   0]\n",
            " [  0   1 426  34   0   0   0   0   0   0   0  18   0]\n",
            " [  0   1  17 448   0   0   0   0   0   0   0   9   0]\n",
            " [  0   0   0   0 433  19   0   0   2   0   0   0   0]\n",
            " [  0   0   0   0  14 469   3   0   0   0   0   1   0]\n",
            " [  6  11   7   5   4  15 471  14   4   4   1  39   1]\n",
            " [  0   0   0   0   0   0  18 284  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 614  13   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9 700  12  15   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14 481  17   0]\n",
            " [  5  16  11  12   1  14  40   6   2   5   1 988   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  26 348]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       358\n",
            "         100       0.91      0.93      0.92       438\n",
            "         200       0.92      0.89      0.90       479\n",
            "         300       0.90      0.94      0.92       475\n",
            "        1000       0.96      0.95      0.96       454\n",
            "        1100       0.91      0.96      0.93       487\n",
            "        1200       0.89      0.81      0.85       582\n",
            "        1300       0.93      0.89      0.91       318\n",
            "        2000       0.95      0.98      0.96       627\n",
            "        2100       0.95      0.95      0.95       736\n",
            "        2200       0.97      0.94      0.96       512\n",
            "        2300       0.88      0.89      0.89      1105\n",
            "        2400       0.99      0.93      0.96       375\n",
            "\n",
            "    accuracy                           0.92      6946\n",
            "   macro avg       0.93      0.93      0.93      6946\n",
            "weighted avg       0.92      0.92      0.92      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioy_KXKh9_63",
        "outputId": "98d8c190-9022-4bcb-add8-ed2ffd7084a5"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "classifier = DecisionTreeClassifier(max_depth=2)\r\n",
        "classifier.fit(X_train, Y_train['newfeature'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "y_pred_pro=classifier.predict_proba(X_test)\r\n",
        "print(y_pred_pro)\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "\r\n",
        "\r\n",
        "classifier.fit(X_train, Y_train['FLOOR'])\r\n",
        "y_pred = classifier.predict(X_test)\r\n",
        "y_pred_pro=classifier.predict_proba(X_test)\r\n",
        "print(y_pred_pro)\r\n",
        "print(confusion_matrix(Y_test['FLOOR'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['FLOOR'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.06803644 0.08897073 0.09342896 ... 0.04274084 0.08993991 0.05902307]\n",
            " [0.         0.         0.         ... 0.05932203 0.10653753 0.01331719]\n",
            " [0.         0.         0.         ... 0.00248756 0.00995025 0.        ]\n",
            " ...\n",
            " [0.06803644 0.08897073 0.09342896 ... 0.04274084 0.08993991 0.05902307]\n",
            " [0.         0.         0.         ... 0.26648097 0.55663881 0.05803157]\n",
            " [0.         0.         0.         ... 0.26648097 0.55663881 0.05803157]]\n",
            "[[  0   0   0   0   0   0 358   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 438   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 479   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 475   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 454   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 487   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 558   0   5   8   0  11   0]\n",
            " [  0   0   0   0   0   0 318   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 185   0 317 115   0  10   0]\n",
            " [  0   0   0   0   0   0 351   0  45 225   0 115   0]\n",
            " [  0   0   0   0   0   0 217   0   3  28   0 264   0]\n",
            " [  0   0   0   0   0   0 452   0   2  35   0 616   0]\n",
            " [  0   0   0   0   0   0 309   0   0   1   0  65   0]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       358\n",
            "         100       0.00      0.00      0.00       438\n",
            "         200       0.00      0.00      0.00       479\n",
            "         300       0.00      0.00      0.00       475\n",
            "        1000       0.00      0.00      0.00       454\n",
            "        1100       0.00      0.00      0.00       487\n",
            "        1200       0.11      0.96      0.20       582\n",
            "        1300       0.00      0.00      0.00       318\n",
            "        2000       0.85      0.51      0.63       627\n",
            "        2100       0.55      0.31      0.39       736\n",
            "        2200       0.00      0.00      0.00       512\n",
            "        2300       0.57      0.56      0.56      1105\n",
            "        2400       0.00      0.00      0.00       375\n",
            "\n",
            "    accuracy                           0.25      6946\n",
            "   macro avg       0.16      0.18      0.14      6946\n",
            "weighted avg       0.23      0.25      0.20      6946\n",
            " new combined feature \n",
            "\n",
            "[[0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]\n",
            " [0.6219346  0.3113079  0.04700272 0.01907357 0.0006812 ]\n",
            " [0.6219346  0.3113079  0.04700272 0.01907357 0.0006812 ]\n",
            " ...\n",
            " [0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]\n",
            " [0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]\n",
            " [0.18794427 0.26433513 0.2725808  0.25372003 0.02141977]]\n",
            "[[ 421    0 1002   16    0]\n",
            " [ 240    0 1368   53    0]\n",
            " [  33    0 1372  159    9]\n",
            " [  13    0 1369  500   16]\n",
            " [   1    0   94   77  203]] new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.29      0.39      1439\n",
            "           1       0.00      0.00      0.00      1661\n",
            "           2       0.26      0.87      0.40      1573\n",
            "           3       0.62      0.26      0.37      1898\n",
            "           4       0.89      0.54      0.67       375\n",
            "\n",
            "    accuracy                           0.36      6946\n",
            "   macro avg       0.47      0.39      0.37      6946\n",
            "weighted avg       0.40      0.36      0.31      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQiYm9fqAFuz",
        "outputId": "1042d273-e730-4ef3-cfd2-0a48859095f2"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import VotingClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "log_clf = LogisticRegression()\r\n",
        "rnd_clf = RandomForestClassifier()\r\n",
        "svm_clf = SVC()\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc',svm_clf)],\r\n",
        "                              voting= 'hard')\r\n",
        "voting_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "for clf in (log_clf,rnd_clf, svm_clf,voting_clf):\r\n",
        "    clf.fit(X_train,Y_train['newfeature'])\r\n",
        "    y_pred= clf.predict(X_test)\r\n",
        "    print(accuracy_score(Y_test['newfeature'],y_pred))\r\n",
        "    print(\"***********************************\")\r\n",
        "    print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "    print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9067088972070256\n",
            "***********************************\n",
            "[[335  21   0   0   0   0   0   0   0   0   0   2   0]\n",
            " [ 27 387  11   0   0   0   4   0   0   0   0   9   0]\n",
            " [  0   8 425  35   0   1   3   0   0   0   0   7   0]\n",
            " [  0   1  30 440   0   0   0   0   0   0   0   4   0]\n",
            " [  0   0   0   0 434  17   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0  26 444  14   0   0   0   0   3   0]\n",
            " [  5   9   7   6   8  12 472   8   4   3   1  45   2]\n",
            " [  0   0   0   0   0   0  16 301   0   0   0   1   0]\n",
            " [  0   0   0   0   0   0   0  11 599  17   0   0   0]\n",
            " [  0   0   0   0   0   5   2   0  19 691  17   2   0]\n",
            " [  0   0   0   0   0   0   1   0   0  21 471  19   0]\n",
            " [  6   6   8  11   1  15  60   8   1   9  12 953  15]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  29 346]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.94      0.92       358\n",
            "         100       0.90      0.88      0.89       438\n",
            "         200       0.88      0.89      0.89       479\n",
            "         300       0.89      0.93      0.91       475\n",
            "        1000       0.93      0.96      0.94       454\n",
            "        1100       0.90      0.91      0.91       487\n",
            "        1200       0.82      0.81      0.82       582\n",
            "        1300       0.92      0.95      0.93       318\n",
            "        2000       0.96      0.96      0.96       627\n",
            "        2100       0.93      0.94      0.94       736\n",
            "        2200       0.94      0.92      0.93       512\n",
            "        2300       0.89      0.86      0.87      1105\n",
            "        2400       0.95      0.92      0.94       375\n",
            "\n",
            "    accuracy                           0.91      6946\n",
            "   macro avg       0.91      0.91      0.91      6946\n",
            "weighted avg       0.91      0.91      0.91      6946\n",
            " new combined feature \n",
            "\n",
            "0.9532104808522891\n",
            "***********************************\n",
            "[[357   1   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1 436   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 477   2   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   1 474   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 454   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   4 483   0   0   0   0   0   0   0]\n",
            " [  5  17  13  10   5   6 476   7   6  17   3  15   2]\n",
            " [  0   0   0   0   0   0   1 301  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 627   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   2 734   0   0   0]\n",
            " [  0   0   0   0   0   1   0   0   0   2 506   3   0]\n",
            " [ 11  27  23  24   1  20  33   9   1  15   8 931   2]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   9 365]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       358\n",
            "         100       0.91      1.00      0.95       438\n",
            "         200       0.93      1.00      0.96       479\n",
            "         300       0.93      1.00      0.96       475\n",
            "        1000       0.98      1.00      0.99       454\n",
            "        1100       0.95      0.99      0.97       487\n",
            "        1200       0.93      0.82      0.87       582\n",
            "        1300       0.95      0.95      0.95       318\n",
            "        2000       0.96      1.00      0.98       627\n",
            "        2100       0.96      1.00      0.98       736\n",
            "        2200       0.98      0.99      0.98       512\n",
            "        2300       0.97      0.84      0.90      1105\n",
            "        2400       0.99      0.97      0.98       375\n",
            "\n",
            "    accuracy                           0.95      6946\n",
            "   macro avg       0.95      0.96      0.96      6946\n",
            "weighted avg       0.95      0.95      0.95      6946\n",
            " new combined feature \n",
            "\n",
            "0.9232651885977541\n",
            "***********************************\n",
            "[[344  13   0   0   0   0   0   0   0   0   0   1   0]\n",
            " [ 18 407   4   1   0   0   0   0   0   0   0   8   0]\n",
            " [  0   1 426  34   0   0   0   0   0   0   0  18   0]\n",
            " [  0   1  17 448   0   0   0   0   0   0   0   9   0]\n",
            " [  0   0   0   0 433  19   0   0   2   0   0   0   0]\n",
            " [  0   0   0   0  14 469   3   0   0   0   0   1   0]\n",
            " [  6  11   7   5   4  15 471  14   4   4   1  39   1]\n",
            " [  0   0   0   0   0   0  18 284  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 614  13   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9 700  12  15   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14 481  17   0]\n",
            " [  5  16  11  12   1  14  40   6   2   5   1 988   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  26 348]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       358\n",
            "         100       0.91      0.93      0.92       438\n",
            "         200       0.92      0.89      0.90       479\n",
            "         300       0.90      0.94      0.92       475\n",
            "        1000       0.96      0.95      0.96       454\n",
            "        1100       0.91      0.96      0.93       487\n",
            "        1200       0.89      0.81      0.85       582\n",
            "        1300       0.93      0.89      0.91       318\n",
            "        2000       0.95      0.98      0.96       627\n",
            "        2100       0.95      0.95      0.95       736\n",
            "        2200       0.97      0.94      0.96       512\n",
            "        2300       0.88      0.89      0.89      1105\n",
            "        2400       0.99      0.93      0.96       375\n",
            "\n",
            "    accuracy                           0.92      6946\n",
            "   macro avg       0.93      0.93      0.93      6946\n",
            "weighted avg       0.92      0.92      0.92      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9369421249640081\n",
            "***********************************\n",
            "[[349   9   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 17 415   5   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   4 450  25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1  11 463   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 444  10   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  13 473   1   0   0   0   0   0   0]\n",
            " [  7  13  10   9   6  12 477  10   4   4   1  28   1]\n",
            " [  0   0   0   0   0   0  14 288  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 616  11   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9 718   9   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0  11 492   8   0]\n",
            " [  5  17  22  15   1  19  39   6   2   4   1 970   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  21 353]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95       358\n",
            "         100       0.90      0.95      0.93       438\n",
            "         200       0.90      0.94      0.92       479\n",
            "         300       0.90      0.97      0.94       475\n",
            "        1000       0.96      0.98      0.97       454\n",
            "        1100       0.92      0.97      0.95       487\n",
            "        1200       0.90      0.82      0.86       582\n",
            "        1300       0.95      0.91      0.93       318\n",
            "        2000       0.95      0.98      0.97       627\n",
            "        2100       0.96      0.98      0.97       736\n",
            "        2200       0.98      0.96      0.97       512\n",
            "        2300       0.94      0.88      0.91      1105\n",
            "        2400       0.99      0.94      0.96       375\n",
            "\n",
            "    accuracy                           0.94      6946\n",
            "   macro avg       0.94      0.94      0.94      6946\n",
            "weighted avg       0.94      0.94      0.94      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cugZykjaFirv",
        "outputId": "b860b19f-3121-4073-8727-7e86ef221533"
      },
      "source": [
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=500,max_samples=100, bootstrap=True, n_jobs=-1)\r\n",
        "bag_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "y_pred= bag_clf.predict(X_test)\r\n",
        "y_pred_pro= bag_clf.predict_proba(X_test)\r\n",
        "\r\n",
        "print(\"***********************************\")\r\n",
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(\"***********************************\")\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********************************\n",
            "[[317  37   0   0   0   0   3   0   0   0   0   1   0]\n",
            " [ 22 397  18   1   0   0   0   0   0   0   0   0   0]\n",
            " [  6  17 414  38   0   0   4   0   0   0   0   0   0]\n",
            " [  0   0   8 467   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 373  54  27   0   0   0   0   0   0]\n",
            " [  0   0   0   0  98 356  33   0   0   0   0   0   0]\n",
            " [  3  26  16  14  12  82 382   9   6  17   6   9   0]\n",
            " [  0   0   0   0   0  17  98 203   0   0   0   0   0]\n",
            " [  0   0   0   0   2   0  11   0 608   3   0   3   0]\n",
            " [  0   0   0   0   0   0   0   0  53 649   9  25   0]\n",
            " [  0   0   0   0   0   0   0   0   0  20 407  85   0]\n",
            " [ 13  38  24  26   6  17  37   7   4  13  11 908   1]\n",
            " [  1   0   0   0   0   0   0   0   1   1   0 124 248]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88       358\n",
            "         100       0.77      0.91      0.83       438\n",
            "         200       0.86      0.86      0.86       479\n",
            "         300       0.86      0.98      0.91       475\n",
            "        1000       0.76      0.82      0.79       454\n",
            "        1100       0.68      0.73      0.70       487\n",
            "        1200       0.64      0.66      0.65       582\n",
            "        1300       0.93      0.64      0.76       318\n",
            "        2000       0.90      0.97      0.94       627\n",
            "        2100       0.92      0.88      0.90       736\n",
            "        2200       0.94      0.79      0.86       512\n",
            "        2300       0.79      0.82      0.80      1105\n",
            "        2400       1.00      0.66      0.79       375\n",
            "\n",
            "    accuracy                           0.82      6946\n",
            "   macro avg       0.84      0.82      0.82      6946\n",
            "weighted avg       0.83      0.82      0.82      6946\n",
            " new combined feature \n",
            "\n",
            "***********************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhNeMVNaKsCT",
        "outputId": "6980ed13-664e-418c-ebfb-6ffa3e168a3e"
      },
      "source": [
        "accuracy_score(Y_test['newfeature'], y_pred)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8247912467607256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLElP7UKOexN"
      },
      "source": [
        "rnd_clf= RandomForestClassifier(n_estimators=500,max_leaf_nodes=20,n_jobs=-1)\r\n",
        "rnd_clf.fit(X_train,Y_train['newfeature'])\r\n",
        "y_pred_rf= rnd_clf.predict(X_test)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwE0MgpsYKS5",
        "outputId": "fd8d2aa1-21a9-4731-e52f-c1bd9a33000b"
      },
      "source": [
        "print(confusion_matrix(Y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(Y_test['newfeature'], y_pred),\"new combined feature \\n\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[349   9   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [ 17 415   5   0   0   0   0   0   0   0   0   1   0]\n",
            " [  0   4 450  25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1  11 463   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 444  10   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  13 473   1   0   0   0   0   0   0]\n",
            " [  7  13  10   9   6  12 477  10   4   4   1  28   1]\n",
            " [  0   0   0   0   0   0  14 288  16   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 616  11   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   9 718   9   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0  11 492   8   0]\n",
            " [  5  17  22  15   1  19  39   6   2   4   1 970   4]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0  21 353]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95       358\n",
            "         100       0.90      0.95      0.93       438\n",
            "         200       0.90      0.94      0.92       479\n",
            "         300       0.90      0.97      0.94       475\n",
            "        1000       0.96      0.98      0.97       454\n",
            "        1100       0.92      0.97      0.95       487\n",
            "        1200       0.90      0.82      0.86       582\n",
            "        1300       0.95      0.91      0.93       318\n",
            "        2000       0.95      0.98      0.97       627\n",
            "        2100       0.96      0.98      0.97       736\n",
            "        2200       0.98      0.96      0.97       512\n",
            "        2300       0.94      0.88      0.91      1105\n",
            "        2400       0.99      0.94      0.96       375\n",
            "\n",
            "    accuracy                           0.94      6946\n",
            "   macro avg       0.94      0.94      0.94      6946\n",
            "weighted avg       0.94      0.94      0.94      6946\n",
            " new combined feature \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFdm5ZdaYR8I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}