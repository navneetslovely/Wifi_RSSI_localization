{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simulation1.ipynb",
      "provenance": [],
      "mount_file_id": "1nXZDPRVhJ58kyBSUPhYwEP_PQ_o7Gpr-",
      "authorship_tag": "ABX9TyOGm2b5E1Pw6O7jt3IHDyho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetslovely/Wifi_RSSI_localization/blob/main/simulation1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2l3rMqxuJ5s"
      },
      "source": [
        "# importing required libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.preprocessing import normalize\r\n",
        "import matplotlib as mpl \r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.utils import plot_model\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.ensemble import VotingClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from matplotlib import pyplot\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksu765iGxoc3"
      },
      "source": [
        "#fetching the data from the drive\r\n",
        "fetch_training_sample= '/content/drive/My Drive/UJIndoorLoc/UJIndoorLoc/trainingData.csv'\r\n",
        "fetch_validation_sample= '/content/drive/My Drive/UJIndoorLoc/UJIndoorLoc/validationData.csv'\r\n",
        "                "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQHDzb_yxvDg"
      },
      "source": [
        "#reading the data from CSV file using pandas\r\n",
        "\"\"\"UJIindoorLoc has two files (training and validation) \"\"\"\r\n",
        "training_data = pd.read_csv(fetch_training_sample) # \r\n",
        "validation_data = pd.read_csv(fetch_validation_sample)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pbP6N3aqoeo",
        "outputId": "f8fb2bca-c32d-43ea-fef2-8bba8c55097d"
      },
      "source": [
        "#creating the custom label\r\n",
        "\"\"\"data contain 529 columns. Out of 529, 520 have Access points RSSIs values and rest of are longitude,latitude,buildingid, floor etc.\"\"\"\r\n",
        "#combining the both training and validation data\r\n",
        "data = pd.concat((training_data,validation_data), ignore_index= True)\r\n",
        "#for making new label coverting the data of column(buildingid and floor) into string, so that join opreation can be performed on axix=1 {1= column}  \r\n",
        "data['BUILDINGID']=data.BUILDINGID.astype(str) #buildingid=0,1,2\r\n",
        "data['FLOOR']=data.FLOOR.astype(str) #Floor=0,1,2,3,4,5\r\n",
        "# lambda exp for join opreation and creating the new column for the new values (0.0,0.1,0.2,....,2.5)\r\n",
        "data['newfeature'] = data[['BUILDINGID', 'FLOOR']].apply(lambda x:  '.'.join(x), axis=1) \r\n",
        "data[['newfeature']] = data[['newfeature']].apply(pd.to_numeric) #converting the generated string data into numeric (float)(0.0,0.1,0.2,....,2.5)\r\n",
        "data['newfeature']=1000*data['newfeature']#(0.0,100.0,200.0,300.0,...,2500.0)\r\n",
        "data['newfeature'] = data['newfeature'].astype(int) #changing the float into int(0.0,100.0,200.0,300.0,...,2500.0)\r\n",
        "data.shape "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21048, 530)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhBXQMyHvmn0",
        "outputId": "34b7dcaf-0bd8-4c64-90c1-8b56f62e5b1f"
      },
      "source": [
        "#divide the data into features and labels \r\n",
        "X=data.iloc[:,:520]# features/parameters/dimenssions\r\n",
        "Y=data.iloc[:,520:]# labels/classs/"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       WAP001  WAP002  WAP003  WAP004  ...  WAP517  WAP518  WAP519  WAP520\n",
            "0         100     100     100     100  ...     100     100     100     100\n",
            "1         100     100     100     100  ...     100     100     100     100\n",
            "2         100     100     100     100  ...     100     100     100     100\n",
            "3         100     100     100     100  ...     100     100     100     100\n",
            "4         100     100     100     100  ...     100     100     100     100\n",
            "...       ...     ...     ...     ...  ...     ...     ...     ...     ...\n",
            "21043     100     100     100     100  ...     100     100     100     100\n",
            "21044     100     100     100     100  ...     100     100     100     100\n",
            "21045     100     100     100     100  ...     100     100     100     100\n",
            "21046     100     100     100     100  ...     100     100     100     100\n",
            "21047     100     100     100     100  ...     100     100     100     100\n",
            "\n",
            "[21048 rows x 520 columns]\n",
            "         LONGITUDE      LATITUDE FLOOR  ... PHONEID   TIMESTAMP  newfeature\n",
            "0     -7541.264300  4.864921e+06     2  ...      23  1371713733        1200\n",
            "1     -7536.621200  4.864934e+06     2  ...      23  1371713691        1200\n",
            "2     -7519.152400  4.864950e+06     2  ...      23  1371714095        1200\n",
            "3     -7524.570400  4.864934e+06     2  ...      23  1371713807        1200\n",
            "4     -7632.143600  4.864982e+06     0  ...      13  1369909710           0\n",
            "...            ...           ...   ...  ...     ...         ...         ...\n",
            "21043 -7317.344231  4.864796e+06     3  ...      13  1381156711        2300\n",
            "21044 -7313.731120  4.864792e+06     3  ...      13  1381156730        2300\n",
            "21045 -7637.535798  4.864903e+06     0  ...      13  1381247781           0\n",
            "21046 -7636.654005  4.864905e+06     0  ...      13  1381247807           0\n",
            "21047 -7637.944120  4.864904e+06     0  ...      13  1381247836           0\n",
            "\n",
            "[21048 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycj2HJcFv1SE"
      },
      "source": [
        "X.replace(100,-98, inplace=True)\r\n",
        "X[X < -98]= -98\r\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Fz2EsjyUGS"
      },
      "source": [
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.30, random_state=42)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M8ta8n9I_rS",
        "outputId": "5a4a61bc-af84-4032-edec-eba80667f2df"
      },
      "source": [
        "X.shape[1]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHlFTMh8yqVx"
      },
      "source": [
        "X_train=preprocessing.normalize(X_train)\r\n",
        "X_test=preprocessing.normalize(X_test)\r\n",
        "# scaler = StandardScaler()\r\n",
        "# scaler.fit(X_train)\r\n",
        "# X_train = scaler.transform(X_train)\r\n",
        "# X_test = scaler.transform(X_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRVF_F5aGlEf"
      },
      "source": [
        "\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6v9x1rwywKb"
      },
      "source": [
        "#implementing the multi_layer Perceptron (MLP)  autoencoders custom  model\r\n",
        "# define encoder\r\n",
        "n_inputs = X.shape[1]\r\n",
        "visible = Input(shape=(n_inputs,))\r\n",
        "# encoder level 1\r\n",
        "e = Dense(n_inputs*2)(visible)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# encoder level 2\r\n",
        "e = Dense(n_inputs)(e)\r\n",
        "e = BatchNormalization()(e)\r\n",
        "e = LeakyReLU()(e)\r\n",
        "# bottleneck\r\n",
        "# n_bottleneck = n_inputs\r\n",
        "n_bottleneck = round(float(n_inputs) / 2.0)\r\n",
        "bottleneck = Dense(n_bottleneck)(e)\r\n",
        "# define decoder, level 1\r\n",
        "d = Dense(n_inputs)(bottleneck)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# decoder level 2\r\n",
        "d = Dense(n_inputs*2)(d)\r\n",
        "d = BatchNormalization()(d)\r\n",
        "d = LeakyReLU()(d)\r\n",
        "# output layer\r\n",
        "output = Dense(n_inputs, activation='relu')(d)\r\n",
        "# define autoencoder model\r\n",
        "model = Model(inputs=visible, outputs=output)\r\n",
        "# compile autoencoder model\r\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error')\r\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "67TgKQVJzAvx",
        "outputId": "2acb2333-3e0d-411c-eb1a-9d41d8e421d3"
      },
      "source": [
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder_no_compress.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=100, batch_size=14, verbose=1, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder_no_compress.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder.h5')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1053/1053 [==============================] - 6s 5ms/step - loss: 0.0487 - val_loss: 0.0438\n",
            "Epoch 2/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0439\n",
            "Epoch 3/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 4/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 5/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 6/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 7/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 8/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 9/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 10/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 11/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 12/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 13/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 14/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 15/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 16/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 17/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 18/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 19/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 20/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 21/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 22/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 23/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 24/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 25/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 26/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 27/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 28/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 29/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 30/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 31/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 32/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 33/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 34/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 35/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 36/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 37/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 38/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 39/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 40/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 41/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 42/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 43/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 44/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 45/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 46/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 47/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 48/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 49/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 50/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 51/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 52/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 53/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 54/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 55/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 56/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 57/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 58/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 59/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 60/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 61/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 62/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 63/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 64/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 65/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 66/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 67/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 68/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 69/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 70/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 71/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 72/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 73/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 74/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 75/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 76/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 77/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 78/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 79/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 80/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 81/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 82/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 83/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 84/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 85/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 86/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 87/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 88/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 89/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 90/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 91/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 92/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 93/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 94/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 95/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 96/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 97/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 98/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 99/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 100/100\n",
            "1053/1053 [==============================] - 5s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j-0tZf398Ld3",
        "outputId": "b14b2f39-f8cd-4b46-cc91-12e1073a81c9"
      },
      "source": [
        "# plot the autoencoder\r\n",
        "plot_model(model, 'autoencoder_no_compress_1.png', show_shapes=True)\r\n",
        "# fit the autoencoder model to reconstruct input\r\n",
        "history = model.fit(X_train, X_train, epochs=100, batch_size=10, verbose=1, validation_data=(X_test,X_test))\r\n",
        "# plot loss\r\n",
        "pyplot.plot(history.history['loss'], label='train')\r\n",
        "pyplot.plot(history.history['val_loss'], label='test')\r\n",
        "pyplot.legend()\r\n",
        "pyplot.show()\r\n",
        "# define an encoder model (without the decoder)\r\n",
        "encoder = Model(inputs=visible, outputs=bottleneck)\r\n",
        "plot_model(encoder, 'encoder_no_compress_1.png', show_shapes=True)\r\n",
        "# save the encoder to file\r\n",
        "encoder.save('encoder_1.h5')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 2/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 3/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 4/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 5/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 6/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 7/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 8/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 9/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 10/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 11/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 12/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 13/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 14/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 15/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 16/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 17/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 18/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 19/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 20/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 21/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 22/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 23/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 24/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 25/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 26/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 27/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 28/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 29/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 30/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 31/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 32/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 33/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 34/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 35/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 36/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 37/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 38/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 39/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 40/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 41/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 42/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 43/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 44/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 45/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 46/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 47/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 48/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 49/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 50/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 51/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 52/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 53/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 54/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 55/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 56/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 57/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 58/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 59/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 60/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 61/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 62/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 63/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 64/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 65/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 66/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 67/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 68/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 69/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 70/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 71/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 72/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 73/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 74/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 75/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 76/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 77/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 78/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 79/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 80/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 81/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 82/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 83/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 84/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 85/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 86/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 87/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 88/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 89/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 90/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 91/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 92/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 93/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 94/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 95/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 96/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 97/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 98/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 99/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n",
            "Epoch 100/100\n",
            "1474/1474 [==============================] - 7s 5ms/step - loss: 0.0438 - val_loss: 0.0438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHfe0njUMsdp",
        "outputId": "a3fdf3cc-8f41-4979-bbda-1305a77ba0e3"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\r\n",
        "\r\n",
        "log_clf = LogisticRegression()\r\n",
        "rnd_clf = RandomForestClassifier()\r\n",
        "svm_clf = SVC()\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc',svm_clf)],\r\n",
        "                              voting= 'hard')\r\n",
        "voting_clf.fit(X_train,y_train['newfeature'])\r\n",
        "for clf in (log_clf,rnd_clf, svm_clf,voting_clf):\r\n",
        "    clf.fit(X_train,y_train['newfeature'])\r\n",
        "    y_pred= clf.predict(X_test)\r\n",
        "print(accuracy_score(y_test['newfeature'],y_pred))\r\n",
        "print(confusion_matrix(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "err=mean_absolute_error(y_test['newfeature'], y_pred)\r\n",
        "print(err)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9897070467141726\n",
            "[[340   5   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3 451   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   1 486   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   2 453   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 416   5   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   8 484   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1 418   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   3 300   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  14 569   2   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 694   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0   4 484   2   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 828   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   8 327]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       345\n",
            "         100       0.99      0.99      0.99       454\n",
            "         200       1.00      1.00      1.00       488\n",
            "         300       1.00      1.00      1.00       455\n",
            "        1000       0.98      0.99      0.98       421\n",
            "        1100       0.99      0.98      0.98       495\n",
            "        1200       0.99      1.00      0.99       420\n",
            "        1300       0.95      0.99      0.97       303\n",
            "        2000       1.00      0.97      0.99       585\n",
            "        2100       0.99      1.00      1.00       694\n",
            "        2200       1.00      0.99      0.99       491\n",
            "        2300       0.99      1.00      0.99       829\n",
            "        2400       1.00      0.98      0.99       335\n",
            "\n",
            "    accuracy                           0.99      6315\n",
            "   macro avg       0.99      0.99      0.99      6315\n",
            "weighted avg       0.99      0.99      0.99      6315\n",
            " new combined feature \n",
            "\n",
            "2.5019794140934284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxvY-XB4NaKC",
        "outputId": "27c33c1f-5356-4f6d-c930-497c2787b520"
      },
      "source": [
        "\r\n",
        "encoder = load_model('encoder.h5')\r\n",
        "# encode the train data\r\n",
        "X_train_encode = encoder.predict(X_train)\r\n",
        "# encode the test data\r\n",
        "X_test_encode = encoder.predict(X_test)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "log_clf = LogisticRegression()\r\n",
        "rnd_clf = RandomForestClassifier()\r\n",
        "svm_clf = SVC()\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc',svm_clf)],\r\n",
        "                              voting= 'hard')\r\n",
        "voting_clf.fit(X_train,y_train['newfeature'])\r\n",
        "for clf in (log_clf,rnd_clf, svm_clf,voting_clf):\r\n",
        "    clf.fit(X_train_encode,y_train['newfeature'])\r\n",
        "    y_pred= clf.predict(X_test_encode)\r\n",
        "print(accuracy_score(y_test['newfeature'],y_pred))\r\n",
        "print(confusion_matrix(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "err=mean_absolute_error(y_test['newfeature'], y_pred)\r\n",
        "print(err)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9859065716547902\n",
            "[[336   8   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3 448   3   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1 486   1   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   4 451   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 410   6   3   2   0   0   0   0   0]\n",
            " [  0   0   0   0   6 486   3   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   2 416   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   4 299   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  10 574   1   0   0   0]\n",
            " [  0   0   0   0   0   0   0   1   0 685   8   0   0]\n",
            " [  0   0   0   0   0   0   1   0   0   5 484   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1 826   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  10 325]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       345\n",
            "         100       0.98      0.99      0.98       454\n",
            "         200       0.98      1.00      0.99       488\n",
            "         300       1.00      0.99      0.99       455\n",
            "        1000       0.99      0.97      0.98       421\n",
            "        1100       0.98      0.98      0.98       495\n",
            "        1200       0.97      0.99      0.98       420\n",
            "        1300       0.95      0.99      0.97       303\n",
            "        2000       1.00      0.98      0.99       585\n",
            "        2100       0.99      0.99      0.99       694\n",
            "        2200       0.98      0.99      0.98       491\n",
            "        2300       0.99      1.00      0.99       829\n",
            "        2400       1.00      0.97      0.98       335\n",
            "\n",
            "    accuracy                           0.99      6315\n",
            "   macro avg       0.98      0.98      0.98      6315\n",
            "weighted avg       0.99      0.99      0.99      6315\n",
            " new combined feature \n",
            "\n",
            "2.7553444180522564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJqNjXcN8se",
        "outputId": "34b3a727-aa1d-4a05-e2c3-6c491f046c54"
      },
      "source": [
        "encoder1 = load_model('encoder_1.h5')\r\n",
        "# encode the train data\r\n",
        "X_train_encode = encoder1.predict(X_train)\r\n",
        "# encode the test data\r\n",
        "X_test_encode = encoder1.predict(X_test)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "log_clf = LogisticRegression()\r\n",
        "rnd_clf = RandomForestClassifier()\r\n",
        "svm_clf = SVC()\r\n",
        "\r\n",
        "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc',svm_clf)],\r\n",
        "                              voting= 'hard')\r\n",
        "voting_clf.fit(X_train,y_train['newfeature'])\r\n",
        "for clf in (log_clf,rnd_clf, svm_clf,voting_clf):\r\n",
        "    clf.fit(X_train_encode,y_train['newfeature'])\r\n",
        "    y_pred= clf.predict(X_test_encode)\r\n",
        "print(accuracy_score(y_test['newfeature'],y_pred))\r\n",
        "print(confusion_matrix(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "err=mean_absolute_error(y_test['newfeature'], y_pred)\r\n",
        "print(err)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9135391923990499\n",
            "[[308  35   1   0   0   0   1   0   0   0   0   0   0]\n",
            " [ 16 421  16   0   0   0   1   0   0   0   0   0   0]\n",
            " [  0   5 476   7   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0  12 443   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 353  65   3   0   0   0   0   0   0]\n",
            " [  0   0  10   0  68 391  26   0   0   0   0   0   0]\n",
            " [  0   0   0   0  16   7 394   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  94 209   0   0   0   0   0]\n",
            " [  0   0   0   0   6   0  10   4 561   4   0   0   0]\n",
            " [  0   0   0   0   6   0   1   2  14 665   6   0   0]\n",
            " [  0   0   0   0   1   0   0  10   1  19 443  17   0]\n",
            " [  0   0   0   0   0   0   2  16   3   0   1 805   2]\n",
            " [  0   0   0   0   0   0   0   2   0   0   2  31 300]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.89      0.92       345\n",
            "         100       0.91      0.93      0.92       454\n",
            "         200       0.92      0.98      0.95       488\n",
            "         300       0.98      0.97      0.98       455\n",
            "        1000       0.78      0.84      0.81       421\n",
            "        1100       0.84      0.79      0.82       495\n",
            "        1200       0.74      0.94      0.83       420\n",
            "        1300       0.85      0.69      0.76       303\n",
            "        2000       0.97      0.96      0.96       585\n",
            "        2100       0.97      0.96      0.96       694\n",
            "        2200       0.98      0.90      0.94       491\n",
            "        2300       0.94      0.97      0.96       829\n",
            "        2400       0.99      0.90      0.94       335\n",
            "\n",
            "    accuracy                           0.91      6315\n",
            "   macro avg       0.91      0.90      0.90      6315\n",
            "weighted avg       0.92      0.91      0.91      6315\n",
            " new combined feature \n",
            "\n",
            "18.701504354711005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-UPvyMU4KcT",
        "outputId": "07947ef1-5aec-48cc-e72e-ec2e0a6da042"
      },
      "source": [
        "rnd_clf= RandomForestClassifier()\r\n",
        "rnd_clf.fit(X_train_encode,y_train['newfeature'])\r\n",
        "y_pred_rf= rnd_clf.predict(X_test_encode)\r\n",
        "print(accuracy_score(y_test['newfeature'],y_pred))\r\n",
        "print(confusion_matrix(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "print(classification_report(y_test['newfeature'], y_pred),\"new combined feature \\n\")\r\n",
        "err=mean_absolute_error(y_test['newfeature'], y_pred)\r\n",
        "print(err)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9135391923990499\n",
            "[[308  35   1   0   0   0   1   0   0   0   0   0   0]\n",
            " [ 16 421  16   0   0   0   1   0   0   0   0   0   0]\n",
            " [  0   5 476   7   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0  12 443   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 353  65   3   0   0   0   0   0   0]\n",
            " [  0   0  10   0  68 391  26   0   0   0   0   0   0]\n",
            " [  0   0   0   0  16   7 394   3   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  94 209   0   0   0   0   0]\n",
            " [  0   0   0   0   6   0  10   4 561   4   0   0   0]\n",
            " [  0   0   0   0   6   0   1   2  14 665   6   0   0]\n",
            " [  0   0   0   0   1   0   0  10   1  19 443  17   0]\n",
            " [  0   0   0   0   0   0   2  16   3   0   1 805   2]\n",
            " [  0   0   0   0   0   0   0   2   0   0   2  31 300]] new combined feature \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.89      0.92       345\n",
            "         100       0.91      0.93      0.92       454\n",
            "         200       0.92      0.98      0.95       488\n",
            "         300       0.98      0.97      0.98       455\n",
            "        1000       0.78      0.84      0.81       421\n",
            "        1100       0.84      0.79      0.82       495\n",
            "        1200       0.74      0.94      0.83       420\n",
            "        1300       0.85      0.69      0.76       303\n",
            "        2000       0.97      0.96      0.96       585\n",
            "        2100       0.97      0.96      0.96       694\n",
            "        2200       0.98      0.90      0.94       491\n",
            "        2300       0.94      0.97      0.96       829\n",
            "        2400       0.99      0.90      0.94       335\n",
            "\n",
            "    accuracy                           0.91      6315\n",
            "   macro avg       0.91      0.90      0.90      6315\n",
            "weighted avg       0.92      0.91      0.91      6315\n",
            " new combined feature \n",
            "\n",
            "18.701504354711005\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}